---
id: 'VC_086'
title: 'Query Rewriting for Compression'
card_type: 'V-Card'
purpose: 'Condense verbose or complex queries into minimal, high-efficiency prompts that preserve full intent and clarity under token or UI constraints.'
tags:
- 'prompt-efficiency'
- 'compression'
- 'token-economy'
- 'clarity'
- 'minimalism'
---

## AI PROMPT CONTENT

### Category
Prompt Efficiency

### Core Function
Condenses verbose or complex queries into minimal, high-efficiency prompts while retaining full intent.

### Definition
Ask the model to rewrite long or overloaded instructions into the shortest possible form without sacrificing clarity—useful for token-limited tasks, mobile apps, or command-line interfaces.

### Example

**Original Prompt:**
“Could you please help me create a list of all the ways we might be able to improve team productivity through better scheduling, including meetings and personal time?”
**Compressed:**
“List ways to boost team productivity via improved scheduling (meetings + personal time).”

### Trigger Phrases
   - Compress this prompt for maximum clarity.
   - Rewrite for token-efficiency.
   - Shorten this to core logic only.
   - Minimal version, same intent.

### Related Concepts
   - Compression-Aware Prompting
   - Instruction Abstraction
   - Format Neglect
   - Output Framing

### Use Cases
   - Mobile apps or UI prompts
   - Token-sensitive LLM chains
   - Teaching compact communication
   - LLM-as-function scenarios