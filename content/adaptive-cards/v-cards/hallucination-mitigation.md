---
id: 'VC_044'
title: 'Hallucination Mitigation'
card_type: 'V-Card'
purpose: 'Minimize inaccurate or fabricated outputs by adding grounding, validation steps, and prompts that encourage calibrated uncertainty.'
tags:
- 'hallucination-mitigation'
- 'grounding'
- 'validation'
- 'reality-anchoring'
- 'uncertainty'
- 'rag'
---

## AI PROMPT CONTENT

### Short Definition
Hallucination Mitigation is the strategic use of prompts, guardrails, or retrieval to minimize AI-generated content that is inaccurate, fabricated, or logically inconsistent.

### Domain Focus
   - **Primary:** Error Handling and Trustworthy Generation
   - **Subdomains:** Grounding, validation, reality anchoring

### Utility for AI
   - Reduces misinformation and fabricated outputs
   - Improves factual consistency
   - Encourages the model to admit uncertainty

### Related Methods
   - Retrieval-Augmented Generation (RAG)
   - Epistemic Prompting
   - Fact-Check Triggers

### Use Cases
   - Academic or scientific writing
   - Legal and medical assistance tools
   - Knowledge agents with traceable logic

### Prompt Fragment
    If unsure, respond with “I don’t know” and explain why the source is insufficient.